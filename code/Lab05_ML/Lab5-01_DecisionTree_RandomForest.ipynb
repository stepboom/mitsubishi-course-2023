{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QstCZsRuF3_b"},"source":["# Decision Trees and Random Forests in Python\n","\n","Reference: http://net-informations.com/ds/mla/dtree.htm, https://www.kaggle.com/code\n","\n","Credit (Image) from https://www.osmosis.org/learn/Lordosis,_kyphosis,_and_scoliosis\n","\n","![](https://d16qt3wv6xm098.cloudfront.net/D8vzGbPOSmitZdUZkrleQYi-SZ6ZFOpZ/_.jpg)"]},{"cell_type":"markdown","metadata":{"id":"5uEm3uAvF3_f"},"source":["# Install this package before starting this lab"]},{"cell_type":"markdown","metadata":{"id":"j92jWln_F3_q"},"source":["## Import Libraries"]},{"cell_type":"code","source":["!pip install --upgrade scikit-learn==1.0.2\n","!pip install --upgrade numpy==1.21.5"],"metadata":{"id":"pVcscDzvYFhL"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nbIivDFCF3_t"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bOeoYa4PF3_z"},"source":["## Get the Data"]},{"cell_type":"code","metadata":{"id":"izXJpnR-Gaxq"},"source":["!wget https://github.com/davidjohnnn/all_datasets/raw/master/bay/kyphosis.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SySn7KVvF3_0"},"source":["df = pd.read_csv('kyphosis.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3uB4-QKAF3_5"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c3h2AFIwF4AC"},"source":["## EDA\n","\n","We'll just check out a simple pairplot for this small dataset."]},{"cell_type":"code","metadata":{"id":"UruKW8GRF4AE"},"source":["sns.pairplot(df,hue='Kyphosis',palette='Set1')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k_5ydSXSF4AM"},"source":["## Train Test Split\n","\n","Let's split up the data into a training set and a test set!"]},{"cell_type":"code","metadata":{"id":"9c2LCvBxF4AN"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rp_KOGDF4AQ"},"source":["X = df.drop('Kyphosis',axis=1)\n","y = df['Kyphosis']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXrs_Ty-F4AV"},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.30, random_state=30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"duQ2ccHAF4Ac"},"source":["## Decision Trees\n","\n","We'll start just by training a single decision tree.\n","\n","http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"]},{"cell_type":"code","metadata":{"id":"OQP_7r0VF4Ae"},"source":["from sklearn.tree import DecisionTreeClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySt_2st4F4Ai"},"source":["dtree = DecisionTreeClassifier(min_samples_leaf=10, criterion='entropy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zt3LBaspF4An"},"source":["dtree.fit(X_train,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FhUw7UBPPR9o"},"source":["import pickle\n","filename = 'model.sav'\n","pickle.dump(dtree, open(filename, 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gau8IxEbF4At"},"source":["## Prediction and Evaluation \n","\n","Let's evaluate our decision tree."]},{"cell_type":"code","metadata":{"id":"ighYvYe9PR9r"},"source":["dtree = pickle.load(open(filename,'rb'))\n","dtree"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ho_EYhhrF4At"},"source":["predictions = dtree.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7XnGZIr8F4Aw"},"source":["from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rf4TAlMdF4Az"},"source":["print(classification_report(y_test,predictions,digits=4))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6JjYjtPF4A2"},"source":["print(confusion_matrix(y_test,predictions,labels=['absent','present']))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B_Ltvn4gF4A7"},"source":["## Tree Visualization\n","\n","Scikit learn actually has some built-in visualization capabilities for decision trees, you won't use this often and it requires you to install the pydot library, but here is an example of what it looks like and the code to execute this:"]},{"cell_type":"code","metadata":{"id":"-xrzW6LzF4A8"},"source":["from sklearn import tree\n","tree.plot_tree(dtree)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X.columns) # feature names\n","print(y.unique().tolist()) # class names"],"metadata":{"id":"x7a0W_RfPZVB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fn=X.columns # feature names\n","cn=y.unique().tolist() # class names\n","fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,6), dpi=100)\n","tree.plot_tree(dtree,\n","               feature_names = fn, \n","               class_names=cn,\n","               filled = True);\n","fig.savefig('imagename.png')"],"metadata":{"id":"WA7OxkinPLxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RBCuT_AtOeEv"},"execution_count":null,"outputs":[]}]}