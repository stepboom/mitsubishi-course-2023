{"cells":[{"cell_type":"markdown","source":["# Image classificartion with CNN\n","<br>Last updated on 10/02/2023</br>\n","Objective: We aim to classify images into 10 classes of cifar10 dataset using pytorch.\n","\n","credit : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"],"metadata":{"id":"V-6dBeZeMdCJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ekk2JN6CxGaO"},"outputs":[],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLfp7_zat1oK"},"outputs":[],"source":["from sklearn.exceptions import UndefinedMetricWarning\n","\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cxvk1XNtwxN7"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"arYMLNHx0W5r"},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming that we are on a CUDA machine, this should print a CUDA device:\n","\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FabhyQJBBYnx"},"outputs":[],"source":["transform = transforms.Compose( # transform is from torchvision (only for image)\n","    [transforms.ToTensor(), # image to tensor --> divide by 255   \n","     transforms.Resize((32, 32))])\n","\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kfip5dOFt1oP"},"outputs":[],"source":["torchvision.datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4IRbDPG2xQvo"},"outputs":[],"source":["trainvalset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainset, valset = torch.utils.data.random_split(trainvalset, [40000, 10000])\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n","\n","#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VGzrStTAt1oS"},"outputs":[],"source":["trainset.__len__(), valset.__len__(), testset.__len__()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TA-3nvKQzx_i"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# functions to show an image\n","def imshow(img):\n","    npimg = img.numpy()\n","    plt.figure(figsize=(16,16))\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","# show images\n","nrow = 9\n","imshow(torchvision.utils.make_grid(images, nrow = nrow))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VmNRvP5VJFmt"},"outputs":[],"source":["# print labels\n","for i in range(batch_size//nrow + 1 if batch_size % nrow else 0):\n","  print(' '.join(f'{labels[i*nrow+j]:<3}' for j in range(min(batch_size - i*nrow, nrow))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiM5v7iuz1IC"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5) # 3 input channels, 6 output channels, 5*5 kernel size\n","        self.pool = nn.MaxPool2d(2, 2) # 2*2 kernel size, 2 strides\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(400, 120) # dense input 400 (16*5), output 120\n","        \n","        self.fc2 = nn.Linear(120, 84) # dense input 120, output 84\n","        self.fc3 = nn.Linear(84, 10) # dense input 84, output 10\n","        self.softmax = torch.nn.Softmax(dim=1) # perform softmax at dim[1] (batch,class) \n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = torch.flatten(x,start_dim=1) # flatten all dimensions (dim[1]) except batch (dim[0])\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        x = self.softmax(x)\n","        return x\n","\n","net = CNN().to(device)"]},{"cell_type":"code","source":["!pip install torchinfo"],"metadata":{"id":"uoY3_qNtUL3V"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npHTcpR24sI3"},"outputs":[],"source":["#from torchsummary import summary\n","#summary(net, (3, 100, 100), batch_size = 32)\n","\n","from torchinfo import summary as summary_info\n","print(summary_info(net, input_size = (32, 3, 32, 32))) # (batchsize,channel,width,height)\n","net = net.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5Hyi14cz3x_"},"outputs":[],"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtpjzmgAz6Ru","scrolled":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from tqdm.notebook import tqdm\n","\n","epochs = 20\n","\n","history_train = {'loss':np.zeros(epochs), 'acc':np.zeros(epochs), 'f1-score':np.zeros(epochs)}\n","history_val = {'loss':np.zeros(epochs), 'acc':np.zeros(epochs), 'f1-score':np.zeros(epochs)}\n","min_val_loss = 1e10\n","PATH = './CNN_CIFAR10.pth'\n","\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","    \n","    print(f'epoch {epoch + 1} \\nTraining ...')\n","    y_predict = list()\n","    y_labels = list()\n","    training_loss = 0.0\n","    n = 0\n","    net.train()\n","    for data in tqdm(trainloader):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs) # forward\n","        loss = criterion(outputs, labels) # calculate loss from forward pass\n","        loss.backward() # just calculate\n","        optimizer.step() # update weights here\n","\n","        # aggregate statistics\n","        training_loss += loss.item()\n","        n+=1\n","\n","        y_labels += list(labels.cpu().numpy())\n","        y_predict += list(outputs.argmax(dim=1).cpu().numpy())\n","    \n","    # print statistics\n","    report = classification_report(y_labels, y_predict, digits = 4, output_dict = True)\n","    acc = report[\"accuracy\"]\n","    f1 = report[\"weighted avg\"][\"f1-score\"]\n","    support = report[\"weighted avg\"][\"support\"]\n","    training_loss /= n\n","    print(f\"training loss: {training_loss:.4}, acc: {acc*100:.4}%, f1-score: {f1*100:.4}%, support: {support}\" )\n","    history_train['loss'][epoch] = training_loss\n","    history_train['acc'][epoch] = acc\n","    history_train['f1-score'][epoch] = f1\n","\n","    print('validating ...')\n","    net.eval()\n","    y_predict = list()\n","    y_labels = list()\n","    validation_loss = 0.0\n","    n = 0\n","    with torch.no_grad():\n","        for data in tqdm(valloader):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            validation_loss += loss.item()\n","\n","            y_labels += list(labels.cpu().numpy())\n","            y_predict += list(outputs.argmax(dim=1).cpu().numpy())\n","            n+=1\n","\n","    # print statistics\n","    report = classification_report(y_labels, y_predict, digits = 4, output_dict = True)\n","    acc = report[\"accuracy\"]\n","    f1 = report[\"weighted avg\"][\"f1-score\"]\n","    support = report[\"weighted avg\"][\"support\"]\n","    validation_loss /= n\n","    print(f\"validation loss: {validation_loss:.4}, acc: {acc*100:.4}%, f1-score: {f1*100:.4}%, support: {support}\" )\n","    history_val['loss'][epoch] = validation_loss\n","    history_val['acc'][epoch] = acc\n","    history_val['f1-score'][epoch] = f1\n","    \n","    #save min validation loss\n","    if validation_loss < min_val_loss:\n","        torch.save(net.state_dict(), PATH)\n","        min_val_loss = validation_loss\n","    \n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1sMaKcvt1oZ"},"outputs":[],"source":["min_val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daY-Aq8ut1oa"},"outputs":[],"source":["fig, axs = plt.subplots(3, figsize= (6,10))\n","# loss\n","axs[0].plot(history_train['loss'], label = 'training')\n","axs[0].plot(history_val['loss'], label = 'validation')\n","axs[0].set_title(\"loss\")\n","axs[0].legend()\n","# acc\n","axs[1].plot(history_train['acc'], label = 'training')\n","axs[1].plot(history_val['acc'], label = 'validation')\n","axs[1].set_title(\"acc\")\n","axs[1].legend()\n","# f1-score\n","axs[2].plot(history_train['f1-score'], label = 'training')\n","axs[2].plot(history_val['f1-score'], label = 'validation')\n","axs[2].set_title(\"f1-score\")\n","axs[2].legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mJAMXJvI0GhA"},"outputs":[],"source":["net = CNN().to(device)\n","net.load_state_dict(torch.load(PATH))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"KQ82LNPDt1ob"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n","\n","print('testing ...')\n","y_predict = list()\n","y_labels = list()\n","test_loss = 0.0\n","n = 0\n","with torch.no_grad():\n","    for data in tqdm(testloader):\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        test_loss += loss.item()\n","\n","        y_labels += list(labels.cpu().numpy())\n","        y_predict += list(outputs.argmax(dim=1).cpu().numpy())\n","        n+=1\n","\n","    # print statistics\n","    test_loss /= n\n","    print(f\"testing loss: {test_loss:.4}\" )\n","    \n","    report = classification_report(y_labels, y_predict, digits = 4)\n","    M = confusion_matrix(y_labels, y_predict)\n","    print(report)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=M)\n","    #acc = report[\"accuracy\"]\n","    #f1 = report[\"weighted avg\"][\"f1-score\"]\n","    #support = report[\"weighted avg\"][\"support\"]\n","    #test_loss /= n\n","    #print(f\"validation loss: {test_loss:.4}, acc: {acc*100:.4}%, f1-score: {f1*100:.4}%, support: {support}\" )"]},{"cell_type":"code","source":["disp.plot()\n","plt.show()"],"metadata":{"id":"KJHJeUvwRq3m"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}