{"cells":[{"cell_type":"markdown","source":["# Image classificartion with EfficientNetB0\n","<br>Last updated on 10/02/2023</br>\n","<br>Objective: We aim to classify images into 10 classes of custom animal dataset using EfficientNetB0</br>\n","credit:<br>\n","https://pytorch.org/tutorials/beginner/data_loading_tutorial.html<br>\n","https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html<br>\n","https://www.kaggle.com/datasets/alessiocorrado99/animals10<br>"],"metadata":{"id":"DQePlnWfBRXX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ekk2JN6CxGaO"},"outputs":[],"source":["! nvidia-smi"]},{"cell_type":"markdown","source":["Download dataset"],"metadata":{"id":"j4REbT4iaHQk"}},{"cell_type":"code","source":["!wget https://github.com/stepboom/mitsubishi-course-2023/raw/main/data/Dataset_animal2.zip"],"metadata":{"id":"zn6ZZzyOlQmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip -q -o 'Dataset_animal2.zip' "],"metadata":{"id":"xPUhMGQglliJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qb6KuD9sjfvS"},"outputs":[],"source":["from sklearn.exceptions import UndefinedMetricWarning\n","\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cxvk1XNtwxN7"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"arYMLNHx0W5r"},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming that we are on a CUDA machine, this should print a CUDA device:\n","\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FabhyQJBBYnx"},"outputs":[],"source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","transform_train = transforms.Compose(\n","    [transforms.Resize((230,230)),\n","        transforms.RandomRotation(30,),\n","        transforms.RandomCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276]) #nomalize imagenet pretrain\n","    ])\n","\n","transform = transforms.Compose(\n","    [transforms.Resize((224,224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n","    ])\n","\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4IRbDPG2xQvo"},"outputs":[],"source":["class AnimalDataset(Dataset):\n","    \n","    def __init__(self, \n","                 img_dir, \n","                 transforms=None):\n","        \n","        super().__init__()\n","        label_image = ['butterfly','cat','chicken','cow','dog','elephant','horse','sheep','spider','squirrel']\n","        self.input_dataset = list()\n","        label_num = 0\n","        for label in label_image:\n","            _, __, files = next(os.walk(os.path.join(img_dir,label)))\n","            for image_name in files:\n","                input = [os.path.join(img_dir,label,image_name),label_num] # [image_path, label_num]\n","                self.input_dataset.append(input)\n","            label_num += 1\n","        \n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.input_dataset)\n","\n","    def __getitem__(self, idx): \n","        img = Image.open(self.input_dataset[idx][0]).convert('RGB')\n","        x = self.transforms(img)\n","        y = self.input_dataset[idx][1]\n","        return x,y\n","\n","trainset = AnimalDataset('./Dataset_animal2/train',transform_train)\n","valset = AnimalDataset('./Dataset_animal2/val',transform)\n","testset = AnimalDataset('./Dataset_animal2/test',transform)\n","\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n","\n","#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Igfnh4pXjfvW"},"outputs":[],"source":["trainset.__len__(), valset.__len__(), testset.__len__()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TA-3nvKQzx_i"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# functions to show an image\n","def imshow(img):\n","    img = img*torch.tensor([0.267, 0.256, 0.276]).mean() + torch.tensor([0.507, 0.487, 0.441]).mean()     # unnormalize\n","    npimg = img.numpy()\n","    plt.figure(figsize=(16,16))\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","# show images\n","nrow = 9\n","imshow(torchvision.utils.make_grid(images, nrow = nrow))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VmNRvP5VJFmt"},"outputs":[],"source":["# print labels\n","for i in range(batch_size//nrow + 1 if batch_size % nrow else 0):\n","  print(' '.join(f'{labels[i*nrow+j]:<3}' for j in range(min(batch_size - i*nrow, nrow))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiM5v7iuz1IC"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","#pretrain_weight = torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n","#net = torchvision.models.efficientnet_v2_s(weights = pretrain_weight)\n","#net.classifier[1] = nn.Linear(1280, 102)\n","#net = net.to(device)\n","#mobile_net \n","num_classes=10\n","model_ft = torchvision.models.efficientnet_b0(pretrained=True)\n","model_ft.classifier[-1] = nn.Sequential(\n","    nn.Linear(in_features=1280, out_features=num_classes),\n","    nn.Softmax(dim=1)\n","        )\n","\n","net = model_ft.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npHTcpR24sI3"},"outputs":[],"source":["from torchsummary import summary\n","summary(net, (3, 224, 224), batch_size = 64)\n","#from torchinfo import summary as summary_info\n","#summary_info(net, input_size = (128, 3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5Hyi14cz3x_"},"outputs":[],"source":["import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.02, momentum=0.9)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtpjzmgAz6Ru","scrolled":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","from tqdm.notebook import tqdm\n","\n","\n","epochs = 20\n","\n","history_train = {'loss':np.zeros(epochs), 'acc':np.zeros(epochs), 'f1-score':np.zeros(epochs)}\n","history_val = {'loss':np.zeros(epochs), 'acc':np.zeros(epochs), 'f1-score':np.zeros(epochs)}\n","min_val_loss = 1e10\n","PATH = './Animal10-efficientnetb0.pth'\n","\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","    \n","    print(f'epoch {epoch + 1} \\nTraining ...')\n","    net.train()\n","    y_predict = list()\n","    y_labels = list()\n","    training_loss = 0.0\n","    n = 0\n","    with torch.set_grad_enabled(True):\n","        for data in tqdm(trainloader):\n","            \n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # aggregate statistics\n","            training_loss += loss.item()\n","            n+=1\n","\n","            y_labels += list(labels.cpu().numpy())\n","            y_predict += list(outputs.argmax(dim=1).cpu().numpy())\n","    scheduler.step()\n","\n","    # print statistics\n","    report = classification_report(y_labels, y_predict, digits = 4, output_dict = True)\n","    acc = report[\"accuracy\"]\n","    f1 = report[\"weighted avg\"][\"f1-score\"]\n","    support = report[\"weighted avg\"][\"support\"]\n","    training_loss /= n\n","    print(f\"training loss: {training_loss:.4}, acc: {acc*100:.4}%, f1-score: {f1*100:.4}%, support: {support}\" )\n","    history_train['loss'][epoch] = training_loss\n","    history_train['acc'][epoch] = acc\n","    history_train['f1-score'][epoch] = f1\n","\n","    print('validating ...')\n","    net.eval()\n","    \n","    optimizer.zero_grad()\n","    \n","    y_predict = list()\n","    y_labels = list()\n","    validation_loss = 0.0\n","    n = 0\n","    with torch.no_grad():\n","        for data in tqdm(valloader):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            validation_loss += loss.item()\n","\n","            y_labels += list(labels.cpu().numpy())\n","            y_predict += list(outputs.argmax(dim=1).cpu().numpy())\n","            n+=1\n","\n","    # print statistics\n","    report = classification_report(y_labels, y_predict, digits = 4, output_dict = True)\n","    acc = report[\"accuracy\"]\n","    f1 = report[\"weighted avg\"][\"f1-score\"]\n","    support = report[\"weighted avg\"][\"support\"]\n","    validation_loss /= n\n","    print(f\"validation loss: {validation_loss:.4}, acc: {acc*100:.4}%, f1-score: {f1*100:.4}%, support: {support}\" )\n","    history_val['loss'][epoch] = validation_loss\n","    history_val['acc'][epoch] = acc\n","    history_val['f1-score'][epoch] = f1\n","    \n","    #save min validation loss\n","    if validation_loss < min_val_loss:\n","        torch.save(net.state_dict(), PATH)\n","        min_val_loss = validation_loss     \n","    \n","print('Finished Training')"]},{"cell_type":"code","source":["min_val_loss"],"metadata":{"id":"97Y1L-1vpZTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(3, figsize= (6,10))\n","# loss\n","axs[0].plot(history_train['loss'], label = 'training')\n","axs[0].plot(history_val['loss'], label = 'validation')\n","axs[0].set_title(\"loss\")\n","axs[0].legend()\n","# acc\n","axs[1].plot(history_train['acc'], label = 'training')\n","axs[1].plot(history_val['acc'], label = 'validation')\n","axs[1].set_title(\"acc\")\n","axs[1].legend()\n","# f1-score\n","axs[2].plot(history_train['f1-score'], label = 'training')\n","axs[2].plot(history_val['f1-score'], label = 'validation')\n","axs[2].set_title(\"f1-score\")\n","axs[2].legend()\n","plt.show()"],"metadata":{"id":"993VrUFblBS1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mJAMXJvI0GhA"},"outputs":[],"source":["PATH = './Animal10-efficientnetb0.pth'\n","net.load_state_dict(torch.load(PATH))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"9CA_ElQdjfvh"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n","\n","\n","print('testing ...')\n","y_predict = list()\n","y_labels = list()\n","test_loss = 0.0\n","n = 0\n","with torch.no_grad():\n","    for data in tqdm(testloader):\n","        net.eval()\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        test_loss += loss.item()\n","\n","        y_labels += list(labels.cpu().numpy())\n","        y_predict += list(outputs.argmax(dim=1).cpu().numpy())\n","        n+=1\n","\n","    # print statistics\n","    test_loss /= n\n","    print(f\"testing loss: {test_loss:.4}\" )\n","    \n","    report = classification_report(y_labels, y_predict, digits = 4)\n","    M = confusion_matrix(y_labels, y_predict)\n","    print(report)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=M)"]},{"cell_type":"code","source":["disp.plot()\n","plt.show()"],"metadata":{"id":"LAMjMggjR2a1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}